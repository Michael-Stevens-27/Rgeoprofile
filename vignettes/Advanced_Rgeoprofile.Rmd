---
title: "Advanced Rgeoprofile"
author: "Michael Stevens"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
bibliography: references.bib
vignette: >
  %\VignetteIndexEntry{Advanced Rgeoprofile}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

## Introduction

In this last Rgeoprofile tutorial we will walk through some of the more advanced features of the package. This includes:

* A quick reminder of the first tutorial
* How many source locations are there?
* Allocating crimes to sources
* Extracting peaks from a geoprofile 
* A ring search strategy against a random one
* Using rasters to manipulate a geoprofile
* A summary of using Rgeoprofile 

Once again, we shall load the packages we need for processing the ouput of the model.  

```{r, message = FALSE}
# load packages
library(RgeoProfile)
library(leaflet)
library(raster)
library(sp)
```

## Recalling the first tutorial

In this tutorial we will revisit the analysis from the [first tutorial](https://michael-stevens-27.github.io/Rgeoprofile/articles/Basic_Rgeoprofile.html). I will quickly run through the process that generated our map in the first tutorial. We will then move on to some more advanced functions from RgeoProfile. 

In short, the process we ran through in the first tutorial (and the process we generally run through when using RgeoProfile) was:
 
```{r, echo = FALSE, message = FALSE}
# load the data 
data(LondonExample_crimes)
data(LondonExample_sources)

# assign data
d <- LondonExample_crimes
s <- LondonExample_sources

# read params and mcmc objects
param_dir <- system.file("extdata/params_object.rds", package = "RgeoProfile", mustWork = TRUE)
p <- readRDS(param_dir)

mcmc_dir <- system.file("extdata/mcmc_object.rds", package = "RgeoProfile", mustWork = TRUE)
m <- readRDS(mcmc_dir)
```

```{r, echo = TRUE, eval = FALSE}
# ----------------------------------
### LOAD AND PROCESS THE DATA
# ----------------------------------

# load the data within the Rgeoprofile package using the data() function
data(LondonExample_crimes)
data(LondonExample_sources)

# example data - re-assign object name 
d <- LondonExample_crimes
s <- LondonExample_sources

# process the data
d <- geoData(d$longitude, d$latitude)
s <- geoDataSource(s$longitude, s$latitude)

# ----------------------------------
### BUILD A PARAMETERS OBJECT
# ----------------------------------

# set model and MCMC parameters
p <- geoParams(data = d, 
               sigma_mean = 1, 
               sigma_var = 5, 
               chains = 5, 
               burnin = 1e3, 
               samples = 1e4,
               longitude_cells = 200, 
               latitude_cells = 200, 
               guardRail = 0.1)

# ----------------------------------
### RUN THE MODEL
# ----------------------------------

# run MCMC
m <- geoMCMC(data = d, params = p)

# ----------------------------------
### BUILD A MAP
# ----------------------------------

my_map <- geoPlotLeaflet(surface = m$geoProfile,
                         params = p,
                         data = d, 
                         source = s, 
                         surfaceCols = rev(viridis::plasma(10)),
                         opacity = 0.7,
                         threshold = 0.1,
                         crimeCex = 2,
                         sourceCex = 3,
                         sourceCol = "black",
                         gpLegend = TRUE)
my_map
```

```{r, echo = FALSE, eval = TRUE}
# remake map
my_map <- geoPlotLeaflet(surface = m$geoProfile,
                         params = p,
                         data = d, 
                         source = s, 
                         surfaceCols = rev(viridis::plasma(10)),
                         opacity = 0.7,
                         threshold = 0.1,
                         crimeCex = 4,
                         sourceCex = 5,
                         sourceCol = "black",
                         gpLegend = TRUE)   
my_map
```

## How many source locations are there?

The main objective of geographic profiling is to estimate source locations based on the locations of crimes. This problem becomes complicated when you do not know **how many** source locations there are prior to running the model. This is what makes the Dirichlet process mixture model so powerful. We do not need to specify the number of source locations prior to running the model, it will come up with an estimate for us. The `geoMCMC()` function will create a "unique_groups" object for us that tells us how many source locations there are at every iteration of the MCMC algorithm. 

```{r}
# access the unique_groups object from the MCMC output
groups <- m$unique_groups
head(groups, 20)
```

A quick glance indicates that most of the time the model thinks there are four sources responsible for producing the data. We can summarise this object using the `table()` function. This will count up how many times the model thinks there are x number of sources. 

```{r}
# summarise the unique groupings object
group_table <- table(groups)
print(group_table) # print out the table
```

It's then possible to visualise this table using the `barplot()` function. 

```{r}
# plot the table using the barplot function
barplot(group_table,
        xlab = "Number",
        ylab = "Count",
        main = "Number of source locations")
```

As we can see the model thinks there could be anywhere between two and eleven source locations, but with an emphasis on four and five. Luckily we can verify this since we had data on the crimes and the source locations - we know the model has four sources. 

## Allocation probabilities

Another useful output from the DPM model is the ability to quantify which crimes originated from which source locations. The model's allocation of crimes to source locations is accessible via the `geoPlotAllocation()` function. 

```{r, eval = TRUE}
# get number of crimes
n_crimes <- length(d$longitude)

# plot allocation
geoPlotAllocation(mcmc = m, 
                  xlab = "Crimes",
                  ylab = "Probability",
                  xTicks_on = TRUE,
                  names = 1:n_crimes) 
```

In this allocation plot each vertical strip corresponds to an individual crime where strips are partitioned to represent the probability that said crime originated from a particular source locations. For example, we can see that crime one is made up of three colours, indicating it could be allocated to 3 different sources. However, given over 90% of crime one's strip is a single colour, we believe the model is pretty sure which source this crime should be allocated to. If we instead consider crime twenty one, we can see the model is torn between allocating it to the source associated with dark orange and the one associated with pale yellow.   

## Extracting peaks from a geoprofile 

The geographic profile created by the model allows us to visualise how we might prioritise a search strategy to find the source locations associated with a criminal. The `geoModelSources()` function allows us to extract the explicit peaks of the profile by returning a set of longitudinal/latitudinal points.

```{r}
ms <- geoModelSources(mcmc = m, data = d)
ms

# add peaks to map
# NB requires ggplot2
mapSource <- addCircles(map = my_map,
                        lng = ms$longitude, 
                        lat = ms$latitude,
                        fillColor = "darkgreen",
                        color = "darkgreen",
                        opacity = 1,
                        fillOpacity = 0.5,
                        radius = 75)
mapSource
```

Here we can see the set of points plotted on our map in dark green (with crimes in red and sources in black). **NOTE:** although we now have a set of locations to investigate it must be stressed that **geographic profiling is not an X marks the spot kind of model** (@Rossmo2000). These locations should be used to influence a search strategy into finding the source locations associated with a criminal.   

## A ring search strategy against a random one

So far, we have covered a few different metrics for model success; in the form of a hit score or gini co-effient. Our hitscores tell us what proportion of the area we must search before finding a source location. Hence, the smaller the hit score, the better the model performs. We also noted that a hitscore of 50% is what you would expect with a random search strategy. However, it would be foolish to invest resources into searching an area completely randomly for a criminal, hence we require some default search strategy. @Smith2015 introduces us to the ring search stratgey, in which we search for source locations by starting at each crime and searching radially outwards. We can create a geographic profile based on a ring search strategy via the `geoRing()` function. We then create a geoprofile via the `geoProfile()` function. 

```{r, eval = TRUE}
#------------------------------------------------------------------
# compare to alternative ring search strategy
#------------------------------------------------------------------
# compare to geoprofile based on ring search strategy
surface_ring <- geoRing(params = p, data = d, source = s, mcmc = m)
gp_ring <- geoProfile(surface = surface_ring)

# map of ring search geoprofile
mapRing <- geoPlotLeaflet(params = p, 
                          data = d, 
                          source = s, 
                          surface = gp_ring,
                          crimeCex = 4,
                          sourceCex = 5,
                          sourceCol = "black",
                          surfaceCols = rev(viridis::plasma(10)),
                          threshold = 0.5,
                          gpLegend = TRUE)
mapRing
```

As we can see this process leads us to a geoprofile with a peak on top of every crime location. Let's compare the hit scores of our sources for the ring search to the original profile we created.  

```{r}
# original hitscores
og_hitscores <- geoReportHitscores(params = p, source = s, surface = m$geoProfile)
names(og_hitscores) <- c("lat", "lon", "Original_profile")

# hitscores of ring search geoprofile
hs_ring <- geoReportHitscores(params = p, source = s, surface = gp_ring)
names(hs_ring) <- c("lat", "lon", "Ring_search")

# combine both
cbind(og_hitscores, hs_ring$Ring_search)
```

Clearly the DPM model is performing most efficently, however the ring search gives us a better deafult search strategy than searching our area randomly. 

## Using rasters to manipulate a geoprofile

Finally, RgeoProfile allows us manipulate our geographic profile based on spatial information we have about an area. For example, if a large body of water is present in our search area, then we are certain that this shouldn't be considered in our search strategy. So we need some way to alter the geoprofile accordingly.  

In @Faulkner2017, author's inferred locations associated with poachers responsible for animal deaths within Sav{\'{e}} Valley Conservancy, Zimbabwe. However, the majority of poachers resided outside the conservancy, hence they masked out the conservancy via the `geoMask()` function. The profile can be seen below. 

\  
![](https://github.com/Michael-Stevens-27/Rgeoprofile/raw/workshop/docs/articles/images/poaching.png)
\  

<!-- ```{r, echo = F}
download.file(url = "https://github.com/Michael-Stevens-27/Rgeoprofile/raw/workshop/docs/articles/images/poaching.png",
          destfile = "image.png",
          mode = 'wb')
knitr::include_graphics(path = "image.png")
``` -->

Here, the points in black represent locations associated with illegal hunting incidents and the blue squares are associated with the poacher's source locations. We can also see the outline of Sav{\'{e}} Valley Conservancy where the majority of source locations are outside the Conservancy but all crimes are within it.    

Before we look at how to include different spatial information in our geoprofile, we must first talk about shapefiles. 

### Shapefiles 

A shapefile is a simple format for storing the location and attributes of different geographic features. These features can consist of either geographic points, lines or areas. The attributes could be any kind of variable such as population density, average rainfall, deaths from a disease etc. You can think of a shapefile as a data frame with explicit geographical information embedded inside. In the following example we will have a look at a shapefile for a section of central London.   

```{r, echo = TRUE}
# access built in shapefile from package
north_london_mask <- geoShapefile()

print(north_london_mask)
```

Here we can see the class of this spatial object, its features, extent, co-ordinate reference system and variables/attributes. We won't delve too far into the meaning of each one of these, but as we can see, it's a spatial polygon data frame, meaning our shapefile consists of different areas (or polygons) each yielding a particular value for seven different variables such as `NAME` and `HECTARES`. 

```{r, echo = FALSE, message = FALSE}
# plot shapefile
plot(north_london_mask, col = as.numeric(north_london_mask$NAME))
 
# names of each london borough
north_london_mask$NAME
```

Here we can see the polygons have been plotted together, and we've listed off the name of each London borough in the shapefile. All manner of different shapefiles can be loaded into R. For a list of resources to help with finding shapefiles and other spatial data, see the extra data section of the [geographic profiling resources](https://michael-stevens-27.github.io/Rgeoprofile/articles/GP_resources.html) page.   

### Manipulating a geoprofile post-hoc

Let's say that we are confident our criminal resides somewhere in the London borough of Westminster. We want to use our shapefile to manipulate the geographic profile shown at the beginning of this tutorial to focus search priority within this borough. First we must subset this shapefile so that we only have the information relating to Westminster.     

```{r}
# restrict mask to Westminster
TH_mask <- north_london_mask[north_london_mask$NAME == "Westminster", ]

# plot smaller shapefile
plot(TH_mask)
```

Now that we have the Westminster part of the shapefile we need to use on our geoprofile. Let's say we think there is only a 10% chance that our criminal resides outside the borough of Westminster. Hence we need to scale all probabilities outside the borough by 0.1. To apply our shapefile to the geoprofile, we use the `geoMask()` function.  

```{r}
# apply shapefile to probability surface
prob_masked <- geoMask(probSurface = m$posteriorSurface, 
                       params = p, 
                       mask = TH_mask,
                       maths = "multiply",
                       operation = "outside", 
                       scaleValue = 0.1)

# rank the surface to create the new geoprofile                       
gp_masked <- geoProfile(prob_masked$prob)
```

We have provided the `geoMask()` function with our probability surface and parameters object. We then provide it with the shapefile, and the three arguments following tells the function to **multiply** all values **outside** the shapefile by the **scaleValue** 0.1. Finally, we rank our probability surface using the `geoProfile()` function to create a geoprofile. 

```{r}
# plot new surface
mapMask <- geoPlotLeaflet(params = p, 
                          data = d, 
                          source = s, 
                          surface = gp_masked,
                          threshold = 1,
                          gpLegend = TRUE,
                          opacity = 0.7,
                          crimeCex = 4,
                          sourceCex = 5,
                          sourceCol = "black",)
mapMask
```

Here we can see that the areas inside the borough of Westminster have increased. Let's see what has happened to our hitscores.

```{r}
# original hit scores
og_hitscores <- geoReportHitscores(params = p, source = s, surface = m$geoProfile)
names(og_hitscores) <- c("lat", "lon", "Original_surface")

# hs of masked surface
hs_mask <- geoReportHitscores(params = p, source = s, surface = gp_masked)
names(hs_mask) <- c("lat", "lon", "Manipulated_surface")

cbind(og_hitscores, hs_mask$Manipulated_surface)
```

Notice that the hit scores for sources two and three have improved, since they are within Westminster. However, also notice that hit scores for sources one and four have worsened. This reflects the fact these two sources are outside of Westminster. Let's say that our intuition was the other way around. We now think that the chance of the criminal residing **inside** Westminster is about 10%. 

We change the code such that the `operation` argument is "inside".  

```{r}
# apply shapefile to probability surface
prob_masked <- geoMask(probSurface = m$posteriorSurface, 
                       params = p, 
                       mask = TH_mask,
                       maths = "multiply",
                       operation = "inside", 
                       scaleValue = 0.1)

# rank the surface to create the new geoprofile                       
gp_masked <- geoProfile(prob_masked$prob)

```

```{r, echo = FALSE}
# plot new surface
mapMask <- geoPlotLeaflet(params = p, 
                          data = d, 
                          source = s, 
                          surface = gp_masked,
                          threshold = 1,
                          gpLegend = TRUE,
                          opacity = 0.7,
                          crimeCex = 4,
                          sourceCex = 5,
                          sourceCol = "black",)
mapMask
```

We can see that the search priority has weakened inside Westminster and become tighter outside.  The `geoMask()` comes with many other operations too, see the function documentation for more options. The shapefile used in this tutorial is built into the RgeoProfile package. Any other external shapefile should be loaded into R using the `readOGR()` function from the `rgdal` package. 

```{r, eval = FALSE}
library(rgdal)

# read in external shapefile
readOGR("PATH TO SHAPEFILE/SHAPEFILE NAME.shp")
```

Notice the extension for a shapefile is ".shp".

## A summary of using Rgeoprofile 

Throughout these tutorials we have learnt how to use the Rgeoprofile package. This consisted of learning how to use RgeoProfile for:  

* Checking and loading data
* Building a parameters object
* Running the model
* Plotting maps
* Model success metrics 
* Choosing priors
* Visualising the dispersal distance, sigma
* Visualising the number of sources $K$
* Allocation probabilities
* Extracting peaks from the profiles
* Learning about a better default strategy than a random search
* Shapefiles and manipulating a geoprofile based on other spatial information

Like the R tutorials, these vignettes have covered a lot of information in a short amount of time. For extra help in using and understanding RgeoProfile, see the [extra resources](https://michael-stevens-27.github.io/Rgeoprofile/articles/GP_resources.html) page.   

```{r, echo = FALSE, eval = FALSE}
# command for building doc as pdf
rmarkdown::render("vignettes/XXX.Rmd", "pdf_document", output_dir="/home/mstevens/Desktop/MAIN WORK/Bangor Workshop/PDF_docs/")
```

## References

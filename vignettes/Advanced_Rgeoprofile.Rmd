---
title: "Advanced Rgeoprofile"
author: "Michael Stevens"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
bibliography: references.bib
vignette: >
  %\VignetteIndexEntry{Advanced Rgeoprofile}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

## Introduction

In this last Rgeoprofile tutorial we will walk through some of the more advanced features of the package. This includes:

* How many source locations are there?
* Allocating crimes to sources
* Extracting peaks from a geoprofile 
* A ring search strategy against a random one
* Using rasters to manipulate a geoprofile
* A summary of using Rgeoprofile 

Once again, we shall load the packages we need for processing the ouput of the model.  

```{r, message = FALSE}
# load packages
library(RgeoProfile)
library(leaflet)
library(raster)
```

```{r, echo = FALSE, message = FALSE}

# read params and mcmc objects
param_dir <- system.file("extdata/params_object.rds", package = "RgeoProfile", mustWork = TRUE)
p <- readRDS(param_dir)

mcmc_dir <- system.file("extdata/mcmc_object.rds", package = "RgeoProfile", mustWork = TRUE)
m <- readRDS(mcmc_dir)

# load the data 
data(LondonExample_crimes)
data(LondonExample_sources)

# assign data
d <- LondonExample_crimes
s <- LondonExample_sources

# remake map
my_map <- geoPlotLeaflet(surface = m$geoProfile,
                         params = p,
                         data = d, 
                         source = s, 
                         surfaceCols = rev(viridis::plasma(10)),
                         opacity = 0.7,
                         threshold = 0.1,
                         crimeCex = 4,
                         sourceCex = 5,
                         sourceCol = "black",
                         gpLegend = TRUE)   
```

In this tutorial we will revisit the analysis from the [first tutorial](https://michael-stevens-27.github.io/Rgeoprofile/articles/Basic_Rgeoprofile.html). Recall the geoprofile created in the first tutorial displayed on the map below.

```{r, eval = TRUE, echo = FALSE}
# plot profile on map
my_map
```   

## How many source locations are there?

The main objective of geographic profiling is to estimate source locations based on the locations of crimes. This problem becomes complicated when you do not know **how many** source locations there are prior to running the model. This is what makes the Dirichlet process mixture model so powerful. We do not need to specify the number of source locations prior to running the model, it will come up with an estimate for us. The `geoMCMC()` function will create a "unique_groups" object for us that tells us how many source locations there are at every iteration of the MCMC algorithm. 

```{r}
# access the unique_groups object from the MCMC output
groups <- m$unique_groups
head(groups, 20)
```

A quick glance indicates that most of the time the model thinks there are four sources responsible for producing the data. We can summarise this object using the `table()` function. This will count up how many times the model thinks there are x number of sources. 

```{r}
# summarise the unique groupings object
group_table <- table(groups)
group_table
```

It's then possible to visualise this table using the `barplot()` function. 

```{r}
# plot the table using the barplot function
barplot(group_table,
        xlab = "Number",
        ylab = "Count",
        main = "Number of source locations")
```

As we can see the model thinks there could be anywhere between two and eleven source locations, but with an emphasis on four and five. Luckily we can verify this since we know the model has four source locations. 

## Allocation probabilities

Another useful output from the DPM model is the ability to quantify which crimes originated from which source locations. The model's allocation of crimes to source locations is accessible via the `geoPlotAllocation()` function. 

```{r, eval = TRUE}
# get number of crimes
n_crimes <- length(d$longitude)

# plot allocation
geoPlotAllocation(mcmc = m, 
                  xlab = "Crimes",
                  ylab = "Probability",
                  xTicks_on = TRUE,
                  names = 1:n_crimes) 
```

In this allocation plot each vertical strip corresponds to an individual crime where strips are partitioned to represent the probability that said crime originated from a particular source locations. For example, we can see that crime one is made up of three colours, indicating it could be allocated to 3 different sources. However, given over 90% of crime one's strip is a single colour, we believe the model is pretty sure which source this crime should be allocated to. If we instead consider crime twenty one, we can see the model is torn between allocating it to the source associated with dark orange and the one associated with pale yellow.   

## Extracting peaks from a geoprofile 

The geographic profile created by the model allows us to visualise how we might prioritise a search strategy to find the source locations associated with a criminal. The `geoModelSources()` function allows us to extract the explicit peaks of the profile by returning a set of longitudinal/latitudinal points.


```{r}
# 
ms <- geoModelSources(mcmc = m, data = d)
ms

# add peaks to map
# NB requires ggplot2
mapSource <- addCircles(map = my_map,
                        lng = ms$longitude, 
                        lat = ms$latitude,
                        fillColor = "darkgreen",
                        color = "darkgreen",
                        opacity = 1,
                        fillOpacity = 0.5,
                        radius = 75)
mapSource
```

Here we can see the set of points plotted on our map in dark green (with crimes in red and sources in black). **NOTE:** although we now have a set of locations to investigate it must be stressed that **geographic profiling is not an X marks the spot kind of model** (@Rossmo2000). These locations should be used to influence a search strategy into finding the source locations associated with a criminal.   

## A ring search strategy against a random one

So far, we have covered a few different metrics for model success; in the form of a hit score or gini co-effient. Our hitscores tell us what proportion of the area we must search before finding a source location. Hence, the smaller the hit score, the better the model performs. We also noted that a hitscore of 50% is what you would expect with a random search strategy. However, it would be foolish to invest resources into searching an area completely randomly for a criminal, hence we require some default search strategy. @Smith2015 introduces us to the ring search stratgey, in which we search for source locations by starting at each crime and searching radially outwards. We can create a geographic profile based on a ring search strategy via the `geoRing()` function. We then create a geoprofile via the `geoProfile()` function. 

```{r, eval = TRUE}
#------------------------------------------------------------------
# compare to alternative ring search strategy
#------------------------------------------------------------------
# compare to geoprofile based on ring search strategy
surface_ring <- geoRing(params = p, data = d, source = s, mcmc = m)
gp_ring <- geoProfile(surface = surface_ring)

# map of ring search geoprofile
mapRing <- geoPlotLeaflet(params = p, 
                          data = d, 
                          source = s, 
                          surface = gp_ring,
                          crimeCex = 4,
                          sourceCex = 5,
                          sourceCol = "black",
                          surfaceCols = rev(viridis::plasma(10)),
                          threshold = 0.5,
                          gpLegend = TRUE)
mapRing
```

As we can see this process leads us to a geoprofile with a peak on top of every crime location. Let's compare the hit scores of our sources for the ring search to the original profile we created.  

```{r}
# original hitscores
og_hitscores <- geoReportHitscores(params = p, source = s, surface = m$geoProfile)
names(og_hitscores) <- c("lat", "lon", "Original_profile")

# hitscores of ring search geoprofile
hs_ring <- geoReportHitscores(params = p, source = s, surface = gp_ring)
names(hs_ring) <- c("lat", "lon", "Ring_search")

# combine both
cbind(og_hitscores, hs_ring$Ring_search)
```

Clearly the DPM model is performing most efficently, however the ring search gives us a better deafult search strategy than searching our area randomly. 

## Using rasters to manipulate a geoprofile

Finally, RgeoProfile allows us manipulate our geographic profile based on spatial information we have about an area. For example, if a large body of water is present in our search area, then we are certain that this shouldn't be considered in our search strategy. So we need some way to alter the geoprofile accordingly.  

In @Faulkner2017, author's inferred locations associated with poachers responsible for animal deaths within Sav$\'{e}$ Valley Conservancy, Zimbabwe. However, poachers could not reside within the conservancy, hence they masked out the conservancy via the `geoMask()` function. The profile can be seen below. 

\  
![](https://github.com/Michael-Stevens-27/Rgeoprofile/raw/workshop/docs/articles/images/poaching.png)
\  

Here, the points in black represent locations associated with illegal hunting incidents and the blue squares are associated with the poacher's source locations. We can also see the outline of Sav$\'{e}$ Valley Conservancy where the majority of source locations are outside the Conservancy but all crimes are within it.    

Before we look at how to include different spatial information in our geoprofile, we must first talk about shapefiles. 

### Shapefiles 

A shapefile is a simple format for storing the location and attributes of different geographic features. These features can consist of either geographic points, lines or areas. The attributes could be any kind of variable such as population density, average rainfall, deaths from a disease etc. You can think of a shapefile as a data frame with explicit geographical information embedded inside. In the following example we will have a look at a shapefile for a section of central London.   

```{r, echo = TRUE}
# access built in shapefile from package
north_london_mask <- geoShapefile()
```

Here we can see the class of this spatial object, its features, extent, co-ordinate reference system and variables/attributed. We won't delve too far into the meaning of each one of these, but as we can see, it's a spatial polygon data frame, meaning our shapefile consists of different areas (or polygons) each yielding a particular value for seven different varaibles such as `NAME` and `HECTARES`. 

```{r, echo = FALSE, message = FALSE}
# plot shapefile
plot(north_london_mask, col = north_london_mask$NAME)

# names of each london borough
north_london_mask$NAME
```

Here we can see the polygons have been plotted together, and we've listed off the name of each London borough in the shapefile.

### Manipulating a geoprofile post-hoc

Let's say that we are confident our criminal resides somewhere in the London borough of Westminster. We want to use our shapefile to manipulate the geographic profile shown at the beginning of this tutorial to focus search priority within this borough. First we must subset this shapefile so that we only have the information relating to Westminster.     

```{r}
# restrict mask to Westminster
TH_mask <- north_london_mask[north_london_mask$NAME == "Westminster", ]

# plot smaller shapefile
plot(TH_mask)
```

Now that we have the Westminster part of the shapefile we need to use on our geoprofile. Let's say we think there is only a 10% chance that our criminal resides outside the borough of Westminster. Hence we need to scale all probabilities outside the borough by 0.1. To apply our shapefile to the geoprofile, we use the `geoMask()` function.  

```{r}
# apply shapefile to probability surface
prob_masked <- geoMask(probSurface = m$posteriorSurface, 
                       params = p, 
                       mask = TH_mask,
                       maths = "multiply",
                       operation = "outside", 
                       scaleValue = 0.1)

# rank the surface to create the new geoprofile                       
gp_masked <- geoProfile(prob_masked$prob)
```

We have provided the `geoMask()` function with our probability surface and parameters object. We then provide it with the shapefile, and the three arguments following tells the function to **multiply** all values **outside** the shapefile by the **scaleValue** 0.1. Finally, we rank our probability surface using the `geoProfile()` function to create a geoprofile. 

```{r}
# plot new surface
mapMask <- geoPlotLeaflet(params = p, 
                          data = d, 
                          source = s, 
                          surface = gp_masked,
                          threshold = 1,
                          gpLegend = TRUE,
                          opacity = 0.7,
                          crimeCex = 4,
                          sourceCex = 5,
                          sourceCol = "black",)
mapMask
```

Here we can see that the areas inside the borough of Westminster have increased. Let's see what has happened to our hitscores. 

```{r}
# original hit scores
og_hitscores <- geoReportHitscores(params = p, source = s, surface = m$geoProfile)
names(og_hitscores) <- c("lat", "lon", "Original_surface")

# hs of masked surface
hs_mask <- geoReportHitscores(params = p, source = s, surface = gp_masked)
names(hs_mask) <- c("lat", "lon", "Manipulated_surface")

cbind(og_hitscores, hs_mask$Manipulated_surface)
```

Notice that the hit scores for sources two and three have improved, since they are within Westminster. However, also notice that hit scores for sources one and four have worsened. This reflects the fact these two sources are outside of Westminster. 

## A summary of using Rgeoprofile 

Throughout these tutorials we have learnt how to use the Rgeoprofile package. This consisted of: checking data and loading data, building a parameters object, running the model, plotting maps, measuring results (hs and gini), choosing priors, visualising sigma, visualising K, allocation probabilities, extracting peaks from the profiles, learning about a better default strategy than random, rasters manipulating a profile.

## References
